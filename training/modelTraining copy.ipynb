{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "HLvsAXRe3qp0",
   "metadata": {
    "id": "HLvsAXRe3qp0"
   },
   "source": [
    "# ECE 590 AI Security and Privacy: Model training and fine-tuning\n",
    "### Hiep Nguyen, Jiechen Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0dab0f-20b3-4188-8a9f-21c2a1065904",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb0dab0f-20b3-4188-8a9f-21c2a1065904",
    "outputId": "d15ea828-f528-4cb0-f900-4bc8e3caceff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_gFecCzT0ILv",
   "metadata": {
    "id": "_gFecCzT0ILv"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15bf51f-04cb-4313-9516-f1bbd92ea43d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e15bf51f-04cb-4313-9516-f1bbd92ea43d",
    "outputId": "5274dffd-3f63-40c5-cb89-06b34c670d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    # transforms.Resize((299, 299)),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    # transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "train_set, val_set = random_split(train_data, [40000, 10000])\n",
    "\n",
    "# Define dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C_phzAnT0OrU",
   "metadata": {
    "id": "C_phzAnT0OrU"
   },
   "source": [
    "## Define helper functions to be used during experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcdeae2-844b-4f36-9171-6992186565ea",
   "metadata": {
    "id": "7dcdeae2-844b-4f36-9171-6992186565ea"
   },
   "outputs": [],
   "source": [
    "# This function evaluates a model's accuracy on the validation set\n",
    "# Optionally, one can pass an adversarial patch as an argument to evaluate the model's performance against a patch attack\n",
    "def eval(model, patch=None, target_class=None):\n",
    "  # Stats to use to calculate accuracy after the eval loop\n",
    "  total_correct = 0\n",
    "  total = 0\n",
    "  total_target = 0\n",
    "  # Put model on GPU and switch to eval mode\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "  # Evaluation loop\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "      # Put data on GPU\n",
    "      images = images.to(device)\n",
    "      if patch is not None:\n",
    "        images = apply(patch, images)\n",
    "      labels = labels.to(device)\n",
    "      # Make predictions\n",
    "      predictions = model(images)\n",
    "      predictions = torch.argmax(predictions, dim=1)\n",
    "      # Update validation accuracy information\n",
    "      total += len(images)\n",
    "      num_correct = (predictions == labels).float().sum().item()\n",
    "      total_correct += num_correct\n",
    "      if target_class is not None:\n",
    "        target = torch.zeros(len(images), dtype=torch.long).fill_(target_class).to(device)\n",
    "        num_target = (predictions == target).float().sum().item()\n",
    "        total_target += num_target\n",
    "  # If evaluating the effects of a targeted patch attach, it is nice to see whether or not the model is classifying lots of examples to the target class\n",
    "  if target_class is not None:\n",
    "    target_percentage = total_target / total\n",
    "    print(f\"Percentage of samples predicted as target class {target_class}: {100 * target_percentage}\")\n",
    "  # Calculate accuracy\n",
    "  accuracy = total_correct / total\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c77eea-21cc-4d92-accb-e9076cd0ae0e",
   "metadata": {
    "id": "36c77eea-21cc-4d92-accb-e9076cd0ae0e"
   },
   "outputs": [],
   "source": [
    "# This function is designed to take in a pretrained ResNet model and fine-tune its weights for the CIFAR-10 dataset\n",
    "# The idea is to fine-tune ResNet for the CIFAR-10 dataset (accuracy should be around 82%) and then degrade that performance via an adversarial patch attack\n",
    "def fine_tune_for_cifar10(model, num_epochs=30, model_path=\"resnet10.pth\", lr=0.01):\n",
    "  # Put model on GPU and put model in training mode\n",
    "  model = model.to(device)\n",
    "  model.train()\n",
    "  # Define loss function and optimizer\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.2)\n",
    "  best_accuracy = 0.0\n",
    "  best_model_path = model_path\n",
    "  # Training loop\n",
    "  for i in range(num_epochs):\n",
    "    # Stats to use for calculating accuracy\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    # Iterate through each batch of data\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "      # Put data on GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Make predictions\n",
    "      outputs = model(images)\n",
    "      predictions = outputs\n",
    "      # predictions = outputs.logits if isinstance(outputs, tuple) else outputs\n",
    "\n",
    "      # Calculate loss for the batch\n",
    "      loss = criterion(predictions, labels)\n",
    "      # Gradient descent\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # Update training accuracy information\n",
    "      total += len(images)\n",
    "      predictions = torch.argmax(predictions, dim=1)\n",
    "      num_correct = (predictions == labels).float().sum().item()\n",
    "      total_correct += num_correct\n",
    "    scheduler.step()  # Update the learning rate\n",
    "\n",
    "    # Print training accuracy\n",
    "    print(f\"Epoch {str(i + 1)}: Training accuracy = {str(total_correct / total)}\")\n",
    "    # Print validation accuracy\n",
    "    val_accuracy = eval(model, patch=None, target_class=None)\n",
    "    print(f\"Validation accuracy: {str(val_accuracy)}\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "      best_accuracy = val_accuracy\n",
    "      torch.save(model.state_dict(), best_model_path)\n",
    "      print(f\"Saved new best model with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c26bd8ae-07b4-432a-a673-6fd48c0fc1eb",
   "metadata": {
    "id": "c26bd8ae-07b4-432a-a673-6fd48c0fc1eb"
   },
   "outputs": [],
   "source": [
    "# Apply patch to a batch of images\n",
    "def apply(patch, batch_of_images):\n",
    "  num_images = batch_of_images.shape[0]\n",
    "  patch_size = patch.shape[1]\n",
    "  # Iterate through each image in the batch\n",
    "  for i in range(num_images):\n",
    "    # Rotate the patch by a random number of degrees\n",
    "    degree = random.uniform(0, 360)\n",
    "    patch_rotated = TF.rotate(patch, angle=degree)\n",
    "    # Randomly choose an (x, y) coordinate on the 32x32 CIFAR-10 image\n",
    "    # This coordinate will be where the top left corner of the rotated patch goes\n",
    "    top_left_x = random.randint(0, 31 - patch_size)\n",
    "    top_left_y = random.randint(0, 31 - patch_size)\n",
    "    # Apply the randomly rotated patch at the random location\n",
    "    batch_of_images[i, :, top_left_x:top_left_x+patch_size, top_left_y:top_left_y+patch_size] = patch\n",
    "  return batch_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f2cc52-15f3-4645-a1d6-a44e135ed004",
   "metadata": {
    "id": "00f2cc52-15f3-4645-a1d6-a44e135ed004"
   },
   "outputs": [],
   "source": [
    "# Function to load the best model checkpoint\n",
    "def load_model(model, path, device=device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1e40d9-8fc9-4b1c-b046-edcbbd197bc8",
   "metadata": {
    "id": "ff1e40d9-8fc9-4b1c-b046-edcbbd197bc8"
   },
   "outputs": [],
   "source": [
    "# This function fine-tunes an adversarial patch against a provided whitebox model\n",
    "# Model accuracy against the patch attack is reported at each step\n",
    "def generate_adversarial_patch(model, patch_size, target_class=None, num_epochs=10, lr=1e-1, momentum=0.8, apply=apply):\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  # Initialize patch to all zeros\n",
    "  patch = nn.Parameter(torch.zeros(3, patch_size, patch_size), requires_grad=True)\n",
    "  optimizer = optim.SGD([patch], lr, momentum)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  # Optimize the patch\n",
    "  for i in range(num_epochs):\n",
    "    print(f\"Epoch {str(i + 1)}\")\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "      # Put data on the GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Apply the patch at a random location and with a random rotation for each image in the batch\n",
    "      images = apply(patch, images)\n",
    "      # Make predictions on the patched images\n",
    "      predictions = resnet34(images)\n",
    "      # For an untargeted attack, create false labels by incrementing the true labels by 1\n",
    "      if target_class is None:\n",
    "        false_labels = (labels + 1) % 10\n",
    "      # For a targeted attack, set all the false labels to the target class\n",
    "      else:\n",
    "        false_labels = torch.zeros(len(images), dtype=torch.long).fill_(target_class).to(device)\n",
    "      # Tune the patch\n",
    "      loss = criterion(predictions, false_labels)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    # See how the patch performs\n",
    "    print(f\"Target class: {target_class}\")\n",
    "    accuracy = eval(model, patch=patch, target_class=target_class)\n",
    "    print(f\"Accuracy: {str(accuracy)}\\n\")  \n",
    "  return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a909b997-766e-4acb-bc2b-35b535ebcd5b",
   "metadata": {
    "id": "a909b997-766e-4acb-bc2b-35b535ebcd5b"
   },
   "outputs": [],
   "source": [
    "# This function test the model accuracy on clean test dataset\n",
    "# Optinally, if pass in an adversarial patch, this function test model accuracy, untargetted and targetted ASR\n",
    "def test(model, patch=None, target_class=None, apply=apply):\n",
    "  model.eval()\n",
    "  total = 0\n",
    "  total_correct = 0\n",
    "  total_misclassified = 0\n",
    "  total_targeted_hits = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      if patch is not None:\n",
    "        images = apply(patch, images)\n",
    "\n",
    "      outputs = model(images)\n",
    "      predictions = torch.argmax(outputs, dim=1)\n",
    "      total += labels.size(0)\n",
    "      total_correct += (predictions == labels).sum().item()\n",
    "      total_misclassified += (predictions != labels).sum().item()\n",
    "\n",
    "      if target_class is not None:\n",
    "        targeted_misclassifications = ((predictions != labels) & (predictions == target_class))\n",
    "        total_targeted_hits += targeted_misclassifications.sum().item()\n",
    "\n",
    "  adversarial_accuracy = total_correct / total\n",
    "  untargeted_attack_rate = total_misclassified / total\n",
    "\n",
    "  if patch is not None:\n",
    "    print(f\"Model accuracy with adversarial patch: {adversarial_accuracy * 100:.2f}%\")\n",
    "    print(f\"Untargeted attack success rate on test set: {untargeted_attack_rate * 100:.2f}%\")\n",
    "  else:\n",
    "    print(f\"Model accuracy on clean test set: {adversarial_accuracy * 100:.2f}%\")\n",
    "\n",
    "  if target_class is not None:\n",
    "    targeted_attack_rate = total_targeted_hits / total\n",
    "    print(f\"Targeted attack success rate on test set for class {target_class}: {targeted_attack_rate * 100:.2f}%\")\n",
    "    return adversarial_accuracy, untargeted_attack_rate, targeted_attack_rate\n",
    "  else:\n",
    "    return adversarial_accuracy, untargeted_attack_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fd0d3c9-f23a-423f-8eed-54986125e2cd",
   "metadata": {
    "id": "0fd0d3c9-f23a-423f-8eed-54986125e2cd"
   },
   "outputs": [],
   "source": [
    "# This function takes in a patch and outputs it visually\n",
    "def visualize_patch(patch):\n",
    "    patch = patch.detach()\n",
    "    patch = (patch - patch.min()) / (patch.max() - patch.min())  # Normalize to [0, 1]\n",
    "\n",
    "    # Convert to numpy and transpose dimensions from [C, H, W] to [H, W, C] for visualization\n",
    "    patch_np = patch.cpu().numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(patch_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d7729eb-ea35-4563-8584-bf832068dccc",
   "metadata": {
    "id": "8d7729eb-ea35-4563-8584-bf832068dccc"
   },
   "outputs": [],
   "source": [
    "# This function is used to plot the (untargeted or targeted) ASR v.s. patch size\n",
    "def plot_asr_vs_patch_size(patch_sizes, asr_results):\n",
    "    asr_values = [asr_results[size] * 100 for size in patch_sizes]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(patch_sizes, asr_values, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Attack Success Rate vs Patch Size')\n",
    "    plt.xlabel('Patch Size (pixels)')\n",
    "    plt.ylabel('ASR (%)')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(patch_sizes)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef920b6-6336-4b2e-886a-7ec11386efe0",
   "metadata": {
    "id": "3ef920b6-6336-4b2e-886a-7ec11386efe0"
   },
   "source": [
    "## Fine-tune ResNet18 for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4289f8ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inception3.__init__() got an unexpected keyword argument 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load pre-trained model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inception \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInception3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIMAGENET1K_V1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ResNet is trained on ImageNet, which has 1000 classes\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# So we need to modify the output layer for CIFAR-10, which has 10 classes\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# vgg.fc = nn.Linear(vgg.fc.in_features, 10)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Modify the adaptive pooling layer to handle smaller input sizes\u001b[39;00m\n\u001b[1;32m      9\u001b[0m inception\u001b[38;5;241m.\u001b[39mAuxLogits\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(inception\u001b[38;5;241m.\u001b[39mAuxLogits\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features, \u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Change for CIFAR-10\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Inception3.__init__() got an unexpected keyword argument 'weights'"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "inception = models.Inception3(weights=\"IMAGENET1K_V1\")\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "# vgg.fc = nn.Linear(vgg.fc.in_features, 10)\n",
    "\n",
    "\n",
    "# Modify the adaptive pooling layer to handle smaller input sizes\n",
    "inception.AuxLogits.fc = nn.Linear(inception.AuxLogits.fc.in_features, 10)  # Change for CIFAR-10\n",
    "inception.fc = nn.Linear(inception.fc.in_features, 10)  # Change for CIFAR-10\n",
    "\n",
    "# Modify the pooling layer\n",
    "inception.Mixed_7c = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(1),  # This replaces the fixed pooling layer with adaptive pooling\n",
    "    nn.Dropout(0.5),  # Add dropout for regularization\n",
    "    nn.Linear(inception.fc.in_features, 10)  # Change for CIFAR-10\n",
    ")\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=inception, num_epochs=30, model_path=\"inception.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "inception = load_model(inception, \"inception.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=inception, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "987c0abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Finetune the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mfine_tune_for_cifar10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mefficientnetv2s.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load best model checkpoint\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnetv2s.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mfine_tune_for_cifar10\u001b[0;34m(model, num_epochs, model_path, lr)\u001b[0m\n\u001b[1;32m     22\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m outputs\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# predictions = outputs.logits if isinstance(outputs, tuple) else outputs\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate loss for the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/efficientnet.py:166\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[0;32m--> 166\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstochastic_depth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_v2_s(weights=\"DEFAULT\")\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "model.classifier = nn.Linear(1280, 10)\n",
    "\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=model, num_epochs=30, model_path=\"efficientnetv2s.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "model = load_model(model, \"efficientnetv2s.pth\", device=device)\n",
    "\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=model, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "inception = models.resnet18(weights=\"DEFAULT\")\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "# vgg.fc = nn.Linear(vgg.fc.in_features, 10)\n",
    "inception.fc = nn.Linear(inception.fc.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=inception, num_epochs=30, model_path=\"inception.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "inception = load_model(inception, \"inception.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=inception, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662a5a10-ba13-450a-b843-98ee0d4bc086",
   "metadata": {
    "id": "662a5a10-ba13-450a-b843-98ee0d4bc086"
   },
   "source": [
    "## Experiment 1: Untargeted 8x8 patch attack on ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab68097-7b0b-4dab-93ff-34b147b0be5e",
   "metadata": {
    "id": "cab68097-7b0b-4dab-93ff-34b147b0be5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate adversarial patch\n",
    "patch_untargeted_size8 = generate_adversarial_patch(model=resnet18, patch_size=8)\n",
    "\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_untargeted_size8)\n",
    "\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_untargeted_size8)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb2a1e-f6d6-4ac9-bf43-bf35070726c0",
   "metadata": {
    "id": "7ccb2a1e-f6d6-4ac9-bf43-bf35070726c0"
   },
   "source": [
    "## Experiment 2: The effect of patch size on untargeted attack success rate for ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a4745-2d7c-4a1b-ac47-d26138fc52c4",
   "metadata": {
    "id": "4f7a4745-2d7c-4a1b-ac47-d26138fc52c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate untargeteded ASR for patches of various sizes and plot patch size vs. untargeted ASR\n",
    "patch_sizes = [3, 5, 7, 16]\n",
    "untargetted_asr_results = {}\n",
    "\n",
    "for size in patch_sizes:\n",
    "  patch = generate_adversarial_patch(model=resnet18, patch_size=size)\n",
    "  visualize_patch(patch)\n",
    "  adversarial_accuracy, untargetted_asr = test(model=resnet18, patch=patch)\n",
    "  untargetted_asr_results[size] = untargetted_asr\n",
    "\n",
    "plot_asr_vs_patch_size(patch_sizes, untargetted_asr_results)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0bc71-330c-436a-8dbd-d16dfe7f35ef",
   "metadata": {
    "id": "08c0bc71-330c-436a-8dbd-d16dfe7f35ef"
   },
   "source": [
    "## Experiment 3: Targeted patch attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yR8VesXiLceO",
   "metadata": {
    "id": "yR8VesXiLceO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate targeted adversarial patch\n",
    "patch_targeted_size8 = generate_adversarial_patch(model=resnet18, patch_size=8, target_class=5)\n",
    "\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_targeted_size8)\n",
    "\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d32b237-5078-49d4-a317-edc7631d2e98",
   "metadata": {
    "id": "0d32b237-5078-49d4-a317-edc7631d2e98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_targeted_asr_vs_patch_size(model, target_class):\n",
    "  print(f\"\\nRUNNING EXPERIMENTS FOR TARGET CLASS {target_class}\\n\")\n",
    "  patch_sizes = [3, 5, 7, 16]\n",
    "  targetted_asr_results = {}\n",
    "  for size in patch_sizes:\n",
    "    patch = generate_adversarial_patch(model=model, patch_size=size, target_class=target_class)\n",
    "    visualize_patch(patch)\n",
    "    adversarial_accuracy, untargetted_asr, targetted_asr = test(model=resnet18, patch=patch, target_class=target_class)\n",
    "    targetted_asr_results[size] = targetted_asr\n",
    "  plot_asr_vs_patch_size(patch_sizes, targetted_asr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_AhlWWzD3XFG",
   "metadata": {
    "id": "_AhlWWzD3XFG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target_class in range(10):\n",
    "  plot_targeted_asr_vs_patch_size(resnet18, target_class)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad9912-b17e-4dcb-ab2e-f3ce64c117be",
   "metadata": {
    "id": "aaad9912-b17e-4dcb-ab2e-f3ce64c117be"
   },
   "source": [
    "## Experiment 4: Transferring patches to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2acfab8-fbaa-40ce-9d8d-0c57d3c223d2",
   "metadata": {
    "id": "e2acfab8-fbaa-40ce-9d8d-0c57d3c223d2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "resnet50 = models.resnet50(weights=\"DEFAULT\")\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=resnet50, num_epochs=30, model_path=\"resnet50.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "resnet50 = load_model(resnet50, \"resnet50.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet50, patch=None, target_class=None)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\nTESTING PATCH TRANSFER FROM RESNET18 TO RESNET50\")\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=resnet50, patch=patch_untargeted_size8, target_class=None)\n",
    "\n",
    "# Targeted Attack\n",
    "test(model=resnet50, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64005c4-e6c2-435a-928e-2e0d96038cc0",
   "metadata": {
    "id": "a64005c4-e6c2-435a-928e-2e0d96038cc0"
   },
   "source": [
    "### Test untarget & target attack on VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80466fd-f3f7-4fb7-8d44-c9544dd0346b",
   "metadata": {
    "id": "c80466fd-f3f7-4fb7-8d44-c9544dd0346b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "vgg19 = models.vgg19(weights=\"DEFAULT\")\n",
    "\n",
    "# Get the number of input features to the classifier\n",
    "num_features = vgg19.classifier[-1].in_features\n",
    "\n",
    "# Replace the last layer (classifier) for CIFAR-10, which has 10 classes\n",
    "vgg19.classifier[-1] = nn.Linear(num_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=vgg19, num_epochs=30, model_path=\"vgg19.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "vgg19 = load_model(vgg19, \"vgg19.pth\")\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=vgg19, patch=None, target_class=None)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\nTESTING PATCH TRANSFER FROM RESNET18 TO VGG19\")\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=vgg19, patch=patch_untargeted_size8, target_class=None)\n",
    "\n",
    "# Targeted Attack\n",
    "test(model=vgg19, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d9869-859c-41f6-81ec-68354ee9f502",
   "metadata": {
    "id": "4d7d9869-859c-41f6-81ec-68354ee9f502"
   },
   "source": [
    "### Test untarget & target attack on DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dc4b4-9a41-4aea-8fea-67c829b7192f",
   "metadata": {
    "id": "864dc4b4-9a41-4aea-8fea-67c829b7192f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "densenet121 = models.densenet121(weights=\"DEFAULT\")\n",
    "\n",
    "num_features = densenet121.classifier.in_features  # Get the number of input features\n",
    "densenet121.classifier = nn.Linear(num_features, 10)  # Replace the classifier for CIFAR-10\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=densenet121, num_epochs=60, model_path=\"densenet121.pth\",lr=0.05)\n",
    "\n",
    "# Load best model checkpoint\n",
    "densenet121 = load_model(densenet121, \"densenet121.pth\")\n",
    "# Test model performance on clean test dataset\n",
    "test(model=densenet121, patch=None, target_class=None)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\nTESTING PATCH TRANSFER FROM RESNET18 TO DENSENET121\")\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=densenet121, patch=patch_untargeted_size8, target_class=None)\n",
    "# Targeted Attack\n",
    "test(model=densenet121, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3068d4-fd83-4177-b9e0-56666519c779",
   "metadata": {
    "id": "8b3068d4-fd83-4177-b9e0-56666519c779",
    "outputId": "56a4eaa2-de12-47d9-f7e1-b98de203b83d"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Define the table data\n",
    "table_data = [\n",
    "    [\"Model\", \"Model Accuracy\", \"Untargeted ASR\", \"Targeted ASR\"],\n",
    "    [\"ResNet18\", 0.8314, 0.6688, 0.7954],\n",
    "    [\"ResNet50\", 0.8680, 0.5792, 0.1465],\n",
    "    [\"VGG19\", 0.8843, 0.6252, 0.0892],\n",
    "    [\"DenseNet121\", 0.7008, 0.5744, 0.0423]\n",
    "\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7485f6",
   "metadata": {
    "id": "dd7485f6"
   },
   "source": [
    "## Experiment 5: Creating patches that are robust to more transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb8452f4",
   "metadata": {
    "id": "eb8452f4"
   },
   "outputs": [],
   "source": [
    "# Apply patch to a batch of images with additional transformations (rotation, horizontal flip, vertical flip, color inversion)\n",
    "def apply_extension(patch, batch_of_images):\n",
    "    num_images = batch_of_images.shape[0]\n",
    "    patch_size = patch.shape[1]\n",
    "\n",
    "    # Iterate through each image in the batch\n",
    "    for i in range(num_images):\n",
    "        # Rotate the patch by a random number of degrees\n",
    "        degree = random.uniform(0, 360)\n",
    "        patch_rotated = TF.rotate(patch, angle=degree)\n",
    "\n",
    "        # Apply horizontal flip with 50% probability\n",
    "        if random.random() > 0.5:\n",
    "            patch_rotated = TF.hflip(patch_rotated)\n",
    "\n",
    "        # Apply vertical flip with 50% probability\n",
    "        if random.random() > 0.5:\n",
    "            patch_rotated = TF.vflip(patch_rotated)\n",
    "\n",
    "        # Apply color inversion with 50% probability\n",
    "        if random.random() > 0.5:\n",
    "            patch_rotated = TF.invert(patch_rotated)\n",
    "\n",
    "        # Randomly choose an (x, y) coordinate on the 32x32 CIFAR-10 image\n",
    "        # This coordinate will be where the top left corner of the rotated patch goes\n",
    "        top_left_x = random.randint(0, 31 - patch_size)\n",
    "        top_left_y = random.randint(0, 31 - patch_size)\n",
    "\n",
    "        # Apply the randomly transformed patch at the random location\n",
    "        batch_of_images[i, :, top_left_x:top_left_x+patch_size, top_left_y:top_left_y+patch_size] = patch_rotated\n",
    "\n",
    "    return batch_of_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373a6df",
   "metadata": {
    "id": "7373a6df"
   },
   "outputs": [],
   "source": [
    "# # Load pre-trained model\n",
    "# resnet18ex = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "# # ResNet is trained on ImageNet, which has 1000 classes\n",
    "# # So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "# resnet18ex.fc = nn.Linear(resnet18ex.fc.in_features, 10)\n",
    "\n",
    "# # Finetune the model\n",
    "# fine_tune_for_cifar10(model=resnet18ex, num_epochs=30, model_path=\"resnet18ex.pth\")\n",
    "# # Load best model checkpoint\n",
    "# resnet18ex = load_model(resnet18ex, \"resnet18ex.pth\", device=device)\n",
    "# # Test model performance on clean test dataset\n",
    "test(model=resnet18, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa653734",
   "metadata": {
    "id": "aa653734",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate adversarial patch\n",
    "patch_untarget_ex = generate_adversarial_patch(model=resnet18, patch_size=8, target_class=None, num_epochs=10, lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_untarget_ex)\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254471df",
   "metadata": {
    "id": "254471df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate adversarial patch\n",
    "patch_target_ex = generate_adversarial_patch(model=resnet18, patch_size=8, target_class=5, num_epochs=10, lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_target_ex)\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e061db6-872e-4755-9e6c-1209a68b9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "vgg19 = models.vgg19(weights=\"DEFAULT\")\n",
    "\n",
    "# Get the number of input features to the classifier\n",
    "num_features = vgg19.classifier[-1].in_features\n",
    "\n",
    "# Replace the last layer (classifier) for CIFAR-10, which has 10 classes\n",
    "vgg19.classifier[-1] = nn.Linear(num_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "# fine_tune_for_cifar10(model=vgg19, num_epochs=30, model_path=\"vgg19.pth\")\n",
    "# Load best model checkpoint\n",
    "vgg19 = load_model(vgg19, \"vgg19.pth\", device=device)\n",
    "# Test model performance on clean test dataset\n",
    "test(model=vgg19, patch=None, target_class=None, apply=apply_extension)\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=vgg19, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "# Targeted Attack\n",
    "test(model=vgg19, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ad32f-2faa-413b-96ab-dd80f126c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "densenet121 = models.densenet121(weights=\"DEFAULT\")\n",
    "\n",
    "num_features = densenet121.classifier.in_features  # Get the number of input features\n",
    "densenet121.classifier = nn.Linear(num_features, 10)  # Replace the classifier for CIFAR-10\n",
    "\n",
    "# Finetune the model\n",
    "# fine_tune_for_cifar10(model=densenet121, num_epochs=30, model_path=\"densenet121.pth\")\n",
    "# Load best model checkpoint\n",
    "densenet121 = load_model(densenet121, \"densenet121.pth\", device=device)\n",
    "# Test model performance on clean test dataset\n",
    "test(model=densenet121, patch=None, target_class=None, apply=apply_extension)\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=densenet121, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "# Targeted Attack\n",
    "test(model=densenet121, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416216a-cdf5-474e-a208-a4feb0a544f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "resnet50 = models.resnet50(weights=\"DEFAULT\")\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 10)\n",
    "# Load best model checkpoint\n",
    "resnet50 = load_model(resnet50, \"resnet50.pth\", device=device)\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet50, patch=None, target_class=None, apply=apply_extension)\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=resnet50, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "# Targeted Attack\n",
    "test(model=resnet50, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23733847-fc61-4b3c-96ee-8629f5b78a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the table data\n",
    "table_data = [\n",
    "    [\"Model\", \"Model Accuracy\", \"Untargeted ASR\", \"Targeted ASR\"],\n",
    "    [\"ResNet18\", 0.8314, 0.6727, 0.3592],\n",
    "    [\"ResNet50\", 0.8680, 0.5024, 0.2193],\n",
    "    [\"VGG19\", 0.8843, 0.6930, 0.1035],\n",
    "    [\"DenseNet121\", 0.7008, 0.5750, 0.1206]\n",
    "\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af8021",
   "metadata": {
    "id": "f9af8021"
   },
   "source": [
    "### (Extension) Generate patches with side length of 3,5,7,10,13,16. Visualize patch_sizes v.s. untargeted ASR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42d2d7",
   "metadata": {
    "id": "6c42d2d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patch_sizes = [3, 5, 7, 10, 13, 16]\n",
    "untargetted_asr_results = {}\n",
    "for size in patch_sizes:\n",
    "  patch = generate_adversarial_patch(model=resnet18, patch_size=size, target_class=None, num_epochs=10,\\\n",
    "                                      lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "  visualize_patch(patch)\n",
    "  adversarial_accuracy, untargetted_asr = test(model=resnet18, patch=patch, target_class=None, apply=apply_extension)\n",
    "  untargetted_asr_results[size] = untargetted_asr\n",
    "plot_asr_vs_patch_size(patch_sizes, untargetted_asr_results)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1fd56",
   "metadata": {
    "id": "78c1fd56"
   },
   "source": [
    "### (Extension) Generate patches with side length of 3,5,7,10,13,16. Visualize patch_sizes v.s. targeted ASR. Target class is set to 5 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b05dcf",
   "metadata": {
    "id": "27b05dcf"
   },
   "outputs": [],
   "source": [
    "patch_sizes = [3, 5, 7, 10, 13, 16]\n",
    "targetted_asr_results = {}\n",
    "for size in patch_sizes:\n",
    "  patch = generate_adversarial_patch(model=resnet18, patch_size=size, target_class=5, num_epochs=10, \\\n",
    "                                     lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "  visualize_patch(patch)\n",
    "  adversarial_accuracy, untargetted_asr, targetted_asr = test(model=resnet18, patch=patch, target_class=5, apply=apply_extension)\n",
    "  targetted_asr_results[size] = targetted_asr\n",
    "plot_asr_vs_patch_size(patch_sizes, targetted_asr_results)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7c79a-9aca-4cff-ab47-be95925499ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3dd60-661b-4cc1-a07d-d0060aed2e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

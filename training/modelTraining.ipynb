{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "HLvsAXRe3qp0",
   "metadata": {
    "id": "HLvsAXRe3qp0"
   },
   "source": [
    "# ECE 590 AI Security and Privacy: Model training and fine-tuning\n",
    "### Hiep Nguyen, Jiechen Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0dab0f-20b3-4188-8a9f-21c2a1065904",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb0dab0f-20b3-4188-8a9f-21c2a1065904",
    "outputId": "d15ea828-f528-4cb0-f900-4bc8e3caceff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_gFecCzT0ILv",
   "metadata": {
    "id": "_gFecCzT0ILv"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15bf51f-04cb-4313-9516-f1bbd92ea43d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e15bf51f-04cb-4313-9516-f1bbd92ea43d",
    "outputId": "5274dffd-3f63-40c5-cb89-06b34c670d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "train_set, val_set = random_split(train_data, [40000, 10000])\n",
    "\n",
    "# Define dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a94c9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.6660706..1.8671105].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define transforms for the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Normalize with mean & std\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Classes in CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Function to un-normalize and display the image with label\n",
    "def imshow_with_label(img, label):\n",
    "    img = img / 2 + 0.5  # Unnormalize the image\n",
    "    npimg = img.numpy()  # Convert to numpy array\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Convert from (C, H, W) to (H, W, C)\n",
    "    \n",
    "    # Add label to the image\n",
    "    plt.title(f'Label: dog', fontsize=14, color='black')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Get a random sample from the dataset\n",
    "image, label = train_data[1]  # Replace 0 with any index to get a specific image\n",
    "\n",
    "# Display the image with label on it\n",
    "imshow_with_label(image, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C_phzAnT0OrU",
   "metadata": {
    "id": "C_phzAnT0OrU"
   },
   "source": [
    "## Define helper functions to be used during experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcdeae2-844b-4f36-9171-6992186565ea",
   "metadata": {
    "id": "7dcdeae2-844b-4f36-9171-6992186565ea"
   },
   "outputs": [],
   "source": [
    "# This function evaluates a model's accuracy on the validation set\n",
    "# Optionally, one can pass an adversarial patch as an argument to evaluate the model's performance against a patch attack\n",
    "def eval(model, patch=None, target_class=None):\n",
    "  # Stats to use to calculate accuracy after the eval loop\n",
    "  total_correct = 0\n",
    "  total = 0\n",
    "  total_target = 0\n",
    "  # Put model on GPU and switch to eval mode\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "  # Evaluation loop\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "      # Put data on GPU\n",
    "      images = images.to(device)\n",
    "      if patch is not None:\n",
    "        images = apply(patch, images)\n",
    "      labels = labels.to(device)\n",
    "      # Make predictions\n",
    "      predictions = model(images)\n",
    "      predictions = torch.argmax(predictions, dim=1)\n",
    "      # Update validation accuracy information\n",
    "      total += len(images)\n",
    "      num_correct = (predictions == labels).float().sum().item()\n",
    "      total_correct += num_correct\n",
    "      if target_class is not None:\n",
    "        target = torch.zeros(len(images), dtype=torch.long).fill_(target_class).to(device)\n",
    "        num_target = (predictions == target).float().sum().item()\n",
    "        total_target += num_target\n",
    "  # If evaluating the effects of a targeted patch attach, it is nice to see whether or not the model is classifying lots of examples to the target class\n",
    "  if target_class is not None:\n",
    "    target_percentage = total_target / total\n",
    "    print(f\"Percentage of samples predicted as target class {target_class}: {100 * target_percentage}\")\n",
    "  # Calculate accuracy\n",
    "  accuracy = total_correct / total\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c77eea-21cc-4d92-accb-e9076cd0ae0e",
   "metadata": {
    "id": "36c77eea-21cc-4d92-accb-e9076cd0ae0e"
   },
   "outputs": [],
   "source": [
    "# This function is designed to take in a pretrained ResNet model and fine-tune its weights for the CIFAR-10 dataset\n",
    "# The idea is to fine-tune ResNet for the CIFAR-10 dataset (accuracy should be around 82%) and then degrade that performance via an adversarial patch attack\n",
    "def fine_tune_for_cifar10(model, num_epochs=30, model_path=\"resnet34.pth\", lr=0.01):\n",
    "  # Put model on GPU and put model in training mode\n",
    "  model = model.to(device)\n",
    "  model.train()\n",
    "  # Define loss function and optimizer\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.2)\n",
    "  best_accuracy = 0.0\n",
    "  best_model_path = model_path\n",
    "  # Training loop\n",
    "  for i in range(num_epochs):\n",
    "    # Stats to use for calculating accuracy\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    # Iterate through each batch of data\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "      # Put data on GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Make predictions\n",
    "      predictions = model(images)\n",
    "      # Calculate loss for the batch\n",
    "      loss = criterion(predictions, labels)\n",
    "      # Gradient descent\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # Update training accuracy information\n",
    "      total += len(images)\n",
    "      predictions = torch.argmax(predictions, dim=1)\n",
    "      num_correct = (predictions == labels).float().sum().item()\n",
    "      total_correct += num_correct\n",
    "    scheduler.step()  # Update the learning rate\n",
    "\n",
    "    # Print training accuracy\n",
    "    print(f\"Epoch {str(i + 1)}: Training accuracy = {str(total_correct / total)}\")\n",
    "    # Print validation accuracy\n",
    "    val_accuracy = eval(model, patch=None, target_class=None)\n",
    "    print(f\"Validation accuracy: {str(val_accuracy)}\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "      best_accuracy = val_accuracy\n",
    "      torch.save(model.state_dict(), best_model_path)\n",
    "      print(f\"Saved new best model with accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c26bd8ae-07b4-432a-a673-6fd48c0fc1eb",
   "metadata": {
    "id": "c26bd8ae-07b4-432a-a673-6fd48c0fc1eb"
   },
   "outputs": [],
   "source": [
    "# Apply patch to a batch of images\n",
    "def apply(patch, batch_of_images):\n",
    "  num_images = batch_of_images.shape[0]\n",
    "  patch_size = patch.shape[1]\n",
    "  # Iterate through each image in the batch\n",
    "  for i in range(num_images):\n",
    "    # Rotate the patch by a random number of degrees\n",
    "    degree = random.uniform(0, 360)\n",
    "    patch_rotated = TF.rotate(patch, angle=degree)\n",
    "    # Randomly choose an (x, y) coordinate on the 32x32 CIFAR-10 image\n",
    "    # This coordinate will be where the top left corner of the rotated patch goes\n",
    "    top_left_x = random.randint(0, 31 - patch_size)\n",
    "    top_left_y = random.randint(0, 31 - patch_size)\n",
    "    # Apply the randomly rotated patch at the random location\n",
    "    batch_of_images[i, :, top_left_x:top_left_x+patch_size, top_left_y:top_left_y+patch_size] = patch\n",
    "  return batch_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f2cc52-15f3-4645-a1d6-a44e135ed004",
   "metadata": {
    "id": "00f2cc52-15f3-4645-a1d6-a44e135ed004"
   },
   "outputs": [],
   "source": [
    "# Function to load the best model checkpoint\n",
    "def load_model(model, path, device=device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff1e40d9-8fc9-4b1c-b046-edcbbd197bc8",
   "metadata": {
    "id": "ff1e40d9-8fc9-4b1c-b046-edcbbd197bc8"
   },
   "outputs": [],
   "source": [
    "# This function fine-tunes an adversarial patch against a provided whitebox model\n",
    "# Model accuracy against the patch attack is reported at each step\n",
    "def generate_adversarial_patch(model, patch_size, target_class=None, num_epochs=10, lr=1e-1, momentum=0.8, apply=apply):\n",
    "  model = model.to(device)\n",
    "  model.eval()\n",
    "\n",
    "  # Initialize patch to all zeros\n",
    "  patch = nn.Parameter(torch.zeros(3, patch_size, patch_size), requires_grad=True)\n",
    "  optimizer = optim.SGD([patch], lr, momentum)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  # Optimize the patch\n",
    "  for i in range(num_epochs):\n",
    "    print(f\"Epoch {str(i + 1)}\")\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "      # Put data on the GPU\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      # Apply the patch at a random location and with a random rotation for each image in the batch\n",
    "      images = apply(patch, images)\n",
    "      # Make predictions on the patched images\n",
    "      predictions = resnet34(images)\n",
    "      # For an untargeted attack, create false labels by incrementing the true labels by 1\n",
    "      if target_class is None:\n",
    "        false_labels = (labels + 1) % 10\n",
    "      # For a targeted attack, set all the false labels to the target class\n",
    "      else:\n",
    "        false_labels = torch.zeros(len(images), dtype=torch.long).fill_(target_class).to(device)\n",
    "      # Tune the patch\n",
    "      loss = criterion(predictions, false_labels)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    # See how the patch performs\n",
    "    print(f\"Target class: {target_class}\")\n",
    "    accuracy = eval(model, patch=patch, target_class=target_class)\n",
    "    print(f\"Accuracy: {str(accuracy)}\\n\")  \n",
    "  return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a909b997-766e-4acb-bc2b-35b535ebcd5b",
   "metadata": {
    "id": "a909b997-766e-4acb-bc2b-35b535ebcd5b"
   },
   "outputs": [],
   "source": [
    "# This function test the model accuracy on clean test dataset\n",
    "# Optinally, if pass in an adversarial patch, this function test model accuracy, untargetted and targetted ASR\n",
    "def test(model, patch=None, target_class=None, apply=apply):\n",
    "  model.eval()\n",
    "  total = 0\n",
    "  total_correct = 0\n",
    "  total_misclassified = 0\n",
    "  total_targeted_hits = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      if patch is not None:\n",
    "        images = apply(patch, images)\n",
    "\n",
    "      outputs = model(images)\n",
    "      predictions = torch.argmax(outputs, dim=1)\n",
    "      total += labels.size(0)\n",
    "      total_correct += (predictions == labels).sum().item()\n",
    "      total_misclassified += (predictions != labels).sum().item()\n",
    "\n",
    "      if target_class is not None:\n",
    "        targeted_misclassifications = ((predictions != labels) & (predictions == target_class))\n",
    "        total_targeted_hits += targeted_misclassifications.sum().item()\n",
    "\n",
    "  adversarial_accuracy = total_correct / total\n",
    "  untargeted_attack_rate = total_misclassified / total\n",
    "\n",
    "  if patch is not None:\n",
    "    print(f\"Model accuracy with adversarial patch: {adversarial_accuracy * 100:.2f}%\")\n",
    "    print(f\"Untargeted attack success rate on test set: {untargeted_attack_rate * 100:.2f}%\")\n",
    "  else:\n",
    "    print(f\"Model accuracy on clean test set: {adversarial_accuracy * 100:.2f}%\")\n",
    "\n",
    "  if target_class is not None:\n",
    "    targeted_attack_rate = total_targeted_hits / total\n",
    "    print(f\"Targeted attack success rate on test set for class {target_class}: {targeted_attack_rate * 100:.2f}%\")\n",
    "    return adversarial_accuracy, untargeted_attack_rate, targeted_attack_rate\n",
    "  else:\n",
    "    return adversarial_accuracy, untargeted_attack_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd0d3c9-f23a-423f-8eed-54986125e2cd",
   "metadata": {
    "id": "0fd0d3c9-f23a-423f-8eed-54986125e2cd"
   },
   "outputs": [],
   "source": [
    "# This function takes in a patch and outputs it visually\n",
    "def visualize_patch(patch):\n",
    "    patch = patch.detach()\n",
    "    patch = (patch - patch.min()) / (patch.max() - patch.min())  # Normalize to [0, 1]\n",
    "\n",
    "    # Convert to numpy and transpose dimensions from [C, H, W] to [H, W, C] for visualization\n",
    "    patch_np = patch.cpu().numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(patch_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7729eb-ea35-4563-8584-bf832068dccc",
   "metadata": {
    "id": "8d7729eb-ea35-4563-8584-bf832068dccc"
   },
   "outputs": [],
   "source": [
    "# This function is used to plot the (untargeted or targeted) ASR v.s. patch size\n",
    "def plot_asr_vs_patch_size(patch_sizes, asr_results):\n",
    "    asr_values = [asr_results[size] * 100 for size in patch_sizes]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(patch_sizes, asr_values, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Attack Success Rate vs Patch Size')\n",
    "    plt.xlabel('Patch Size (pixels)')\n",
    "    plt.ylabel('ASR (%)')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(patch_sizes)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef920b6-6336-4b2e-886a-7ec11386efe0",
   "metadata": {
    "id": "3ef920b6-6336-4b2e-886a-7ec11386efe0"
   },
   "source": [
    "## Fine-tune ResNet18 for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae7f907-4717-4181-a806-ba2bff9eca82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eae7f907-4717-4181-a806-ba2bff9eca82",
    "outputId": "81af34fe-0a40-4758-ce69-b0c0ecd2def7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training accuracy = 0.391075\n",
      "Validation accuracy: 0.4617\n",
      "Saved new best model with accuracy: 0.4617\n",
      "Epoch 2: Training accuracy = 0.49895\n",
      "Validation accuracy: 0.5775\n",
      "Saved new best model with accuracy: 0.5775\n",
      "Epoch 3: Training accuracy = 0.596275\n",
      "Validation accuracy: 0.6114\n",
      "Saved new best model with accuracy: 0.6114\n",
      "Epoch 4: Training accuracy = 0.6422\n",
      "Validation accuracy: 0.6415\n",
      "Saved new best model with accuracy: 0.6415\n",
      "Epoch 5: Training accuracy = 0.68185\n",
      "Validation accuracy: 0.6912\n",
      "Saved new best model with accuracy: 0.6912\n",
      "Epoch 6: Training accuracy = 0.710525\n",
      "Validation accuracy: 0.7051\n",
      "Saved new best model with accuracy: 0.7051\n",
      "Epoch 7: Training accuracy = 0.736775\n",
      "Validation accuracy: 0.7235\n",
      "Saved new best model with accuracy: 0.7235\n",
      "Epoch 8: Training accuracy = 0.750625\n",
      "Validation accuracy: 0.7179\n",
      "Epoch 9: Training accuracy = 0.768825\n",
      "Validation accuracy: 0.7461\n",
      "Saved new best model with accuracy: 0.7461\n",
      "Epoch 10: Training accuracy = 0.778725\n",
      "Validation accuracy: 0.7716\n",
      "Saved new best model with accuracy: 0.7716\n",
      "Epoch 11: Training accuracy = 0.791375\n",
      "Validation accuracy: 0.7831\n",
      "Saved new best model with accuracy: 0.7831\n",
      "Epoch 12: Training accuracy = 0.8003\n",
      "Validation accuracy: 0.7783\n",
      "Epoch 13: Training accuracy = 0.80935\n",
      "Validation accuracy: 0.801\n",
      "Saved new best model with accuracy: 0.8010\n",
      "Epoch 14: Training accuracy = 0.8155\n",
      "Validation accuracy: 0.7932\n",
      "Epoch 15: Training accuracy = 0.82165\n",
      "Validation accuracy: 0.7895\n",
      "Epoch 16: Training accuracy = 0.828175\n",
      "Validation accuracy: 0.8073\n",
      "Saved new best model with accuracy: 0.8073\n",
      "Epoch 17: Training accuracy = 0.8345\n",
      "Validation accuracy: 0.8141\n",
      "Saved new best model with accuracy: 0.8141\n",
      "Epoch 18: Training accuracy = 0.837825\n",
      "Validation accuracy: 0.8119\n",
      "Epoch 19: Training accuracy = 0.844275\n",
      "Validation accuracy: 0.8096\n",
      "Epoch 20: Training accuracy = 0.846575\n",
      "Validation accuracy: 0.8224\n",
      "Saved new best model with accuracy: 0.8224\n",
      "Epoch 21: Training accuracy = 0.852825\n",
      "Validation accuracy: 0.8199\n",
      "Epoch 22: Training accuracy = 0.8554\n",
      "Validation accuracy: 0.8135\n",
      "Epoch 23: Training accuracy = 0.862425\n",
      "Validation accuracy: 0.8162\n",
      "Epoch 24: Training accuracy = 0.862675\n",
      "Validation accuracy: 0.8304\n",
      "Saved new best model with accuracy: 0.8304\n",
      "Epoch 25: Training accuracy = 0.86865\n",
      "Validation accuracy: 0.8334\n",
      "Saved new best model with accuracy: 0.8334\n",
      "Epoch 26: Training accuracy = 0.868775\n",
      "Validation accuracy: 0.8214\n",
      "Epoch 27: Training accuracy = 0.8689\n",
      "Validation accuracy: 0.8409\n",
      "Saved new best model with accuracy: 0.8409\n",
      "Epoch 28: Training accuracy = 0.873375\n",
      "Validation accuracy: 0.8355\n",
      "Epoch 29: Training accuracy = 0.8762\n",
      "Validation accuracy: 0.8373\n",
      "Epoch 30: Training accuracy = 0.87955\n",
      "Validation accuracy: 0.8304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 84.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8441, 0.1559)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "from resnet import ResNet20\n",
    "resnet34 = ResNet20()\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet34.linear = nn.Linear(resnet34.linear.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=resnet34, num_epochs=30, model_path=\"resnet20.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "resnet34 = load_model(resnet34, \"resnet20.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet34, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c2ea296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training accuracy = 0.4042\n",
      "Validation accuracy: 0.4947\n",
      "Saved new best model with accuracy: 0.4947\n",
      "Epoch 2: Training accuracy = 0.496575\n",
      "Validation accuracy: 0.5359\n",
      "Saved new best model with accuracy: 0.5359\n",
      "Epoch 3: Training accuracy = 0.576075\n",
      "Validation accuracy: 0.5955\n",
      "Saved new best model with accuracy: 0.5955\n",
      "Epoch 4: Training accuracy = 0.61515\n",
      "Validation accuracy: 0.6114\n",
      "Saved new best model with accuracy: 0.6114\n",
      "Epoch 5: Training accuracy = 0.644975\n",
      "Validation accuracy: 0.6577\n",
      "Saved new best model with accuracy: 0.6577\n",
      "Epoch 6: Training accuracy = 0.666875\n",
      "Validation accuracy: 0.6784\n",
      "Saved new best model with accuracy: 0.6784\n",
      "Epoch 7: Training accuracy = 0.68295\n",
      "Validation accuracy: 0.6778\n",
      "Epoch 8: Training accuracy = 0.701375\n",
      "Validation accuracy: 0.6936\n",
      "Saved new best model with accuracy: 0.6936\n",
      "Epoch 9: Training accuracy = 0.713625\n",
      "Validation accuracy: 0.7274\n",
      "Saved new best model with accuracy: 0.7274\n",
      "Epoch 10: Training accuracy = 0.723875\n",
      "Validation accuracy: 0.7133\n",
      "Epoch 11: Training accuracy = 0.73565\n",
      "Validation accuracy: 0.73\n",
      "Saved new best model with accuracy: 0.7300\n",
      "Epoch 12: Training accuracy = 0.7442\n",
      "Validation accuracy: 0.7412\n",
      "Saved new best model with accuracy: 0.7412\n",
      "Epoch 13: Training accuracy = 0.755\n",
      "Validation accuracy: 0.736\n",
      "Epoch 14: Training accuracy = 0.764025\n",
      "Validation accuracy: 0.7562\n",
      "Saved new best model with accuracy: 0.7562\n",
      "Epoch 15: Training accuracy = 0.7677\n",
      "Validation accuracy: 0.7449\n",
      "Epoch 16: Training accuracy = 0.77525\n",
      "Validation accuracy: 0.755\n",
      "Epoch 17: Training accuracy = 0.779225\n",
      "Validation accuracy: 0.7561\n",
      "Epoch 18: Training accuracy = 0.78025\n",
      "Validation accuracy: 0.776\n",
      "Saved new best model with accuracy: 0.7760\n",
      "Epoch 19: Training accuracy = 0.7891\n",
      "Validation accuracy: 0.7704\n",
      "Epoch 20: Training accuracy = 0.7924\n",
      "Validation accuracy: 0.7699\n",
      "Epoch 21: Training accuracy = 0.793125\n",
      "Validation accuracy: 0.7666\n",
      "Epoch 22: Training accuracy = 0.799775\n",
      "Validation accuracy: 0.7765\n",
      "Saved new best model with accuracy: 0.7765\n",
      "Epoch 23: Training accuracy = 0.799875\n",
      "Validation accuracy: 0.7775\n",
      "Saved new best model with accuracy: 0.7775\n",
      "Epoch 24: Training accuracy = 0.8048\n",
      "Validation accuracy: 0.7828\n",
      "Saved new best model with accuracy: 0.7828\n",
      "Epoch 25: Training accuracy = 0.808275\n",
      "Validation accuracy: 0.7778\n",
      "Epoch 26: Training accuracy = 0.81055\n",
      "Validation accuracy: 0.7639\n",
      "Epoch 27: Training accuracy = 0.8136\n",
      "Validation accuracy: 0.7926\n",
      "Saved new best model with accuracy: 0.7926\n",
      "Epoch 28: Training accuracy = 0.81415\n",
      "Validation accuracy: 0.794\n",
      "Saved new best model with accuracy: 0.7940\n",
      "Epoch 29: Training accuracy = 0.817725\n",
      "Validation accuracy: 0.7978\n",
      "Saved new best model with accuracy: 0.7978\n",
      "Epoch 30: Training accuracy = 0.8172\n",
      "Validation accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 80.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8078, 0.1922)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "from resnet import ResNet10\n",
    "resnet10 = ResNet10()\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet10.linear = nn.Linear(resnet10.linear.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=resnet10, num_epochs=30, model_path=\"resnet10.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "resnet10 = load_model(resnet10, \"resnet10.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet10, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0155bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training accuracy = 0.406325\n",
      "Validation accuracy: 0.5202\n",
      "Saved new best model with accuracy: 0.5202\n",
      "Epoch 2: Training accuracy = 0.5202\n",
      "Validation accuracy: 0.5906\n",
      "Saved new best model with accuracy: 0.5906\n",
      "Epoch 3: Training accuracy = 0.613225\n",
      "Validation accuracy: 0.6215\n",
      "Saved new best model with accuracy: 0.6215\n",
      "Epoch 4: Training accuracy = 0.658075\n",
      "Validation accuracy: 0.6831\n",
      "Saved new best model with accuracy: 0.6831\n",
      "Epoch 5: Training accuracy = 0.69155\n",
      "Validation accuracy: 0.7054\n",
      "Saved new best model with accuracy: 0.7054\n",
      "Epoch 6: Training accuracy = 0.71595\n",
      "Validation accuracy: 0.722\n",
      "Saved new best model with accuracy: 0.7220\n",
      "Epoch 7: Training accuracy = 0.73805\n",
      "Validation accuracy: 0.7348\n",
      "Saved new best model with accuracy: 0.7348\n",
      "Epoch 8: Training accuracy = 0.75455\n",
      "Validation accuracy: 0.7408\n",
      "Saved new best model with accuracy: 0.7408\n",
      "Epoch 9: Training accuracy = 0.76715\n",
      "Validation accuracy: 0.7633\n",
      "Saved new best model with accuracy: 0.7633\n",
      "Epoch 10: Training accuracy = 0.7731\n",
      "Validation accuracy: 0.7103\n",
      "Epoch 11: Training accuracy = 0.786925\n",
      "Validation accuracy: 0.7703\n",
      "Saved new best model with accuracy: 0.7703\n",
      "Epoch 12: Training accuracy = 0.794125\n",
      "Validation accuracy: 0.782\n",
      "Saved new best model with accuracy: 0.7820\n",
      "Epoch 13: Training accuracy = 0.801725\n",
      "Validation accuracy: 0.7805\n",
      "Epoch 14: Training accuracy = 0.809375\n",
      "Validation accuracy: 0.7855\n",
      "Saved new best model with accuracy: 0.7855\n",
      "Epoch 15: Training accuracy = 0.81315\n",
      "Validation accuracy: 0.7931\n",
      "Saved new best model with accuracy: 0.7931\n",
      "Epoch 16: Training accuracy = 0.823125\n",
      "Validation accuracy: 0.803\n",
      "Saved new best model with accuracy: 0.8030\n",
      "Epoch 17: Training accuracy = 0.8234\n",
      "Validation accuracy: 0.7923\n",
      "Epoch 18: Training accuracy = 0.826525\n",
      "Validation accuracy: 0.8073\n",
      "Saved new best model with accuracy: 0.8073\n",
      "Epoch 19: Training accuracy = 0.83565\n",
      "Validation accuracy: 0.8018\n",
      "Epoch 20: Training accuracy = 0.838875\n",
      "Validation accuracy: 0.802\n",
      "Epoch 21: Training accuracy = 0.84095\n",
      "Validation accuracy: 0.8165\n",
      "Saved new best model with accuracy: 0.8165\n",
      "Epoch 22: Training accuracy = 0.845225\n",
      "Validation accuracy: 0.8127\n",
      "Epoch 23: Training accuracy = 0.846225\n",
      "Validation accuracy: 0.8216\n",
      "Saved new best model with accuracy: 0.8216\n",
      "Epoch 24: Training accuracy = 0.849975\n",
      "Validation accuracy: 0.8178\n",
      "Epoch 25: Training accuracy = 0.8517\n",
      "Validation accuracy: 0.8263\n",
      "Saved new best model with accuracy: 0.8263\n",
      "Epoch 26: Training accuracy = 0.856925\n",
      "Validation accuracy: 0.8162\n",
      "Epoch 27: Training accuracy = 0.857075\n",
      "Validation accuracy: 0.822\n",
      "Epoch 28: Training accuracy = 0.858225\n",
      "Validation accuracy: 0.8195\n",
      "Epoch 29: Training accuracy = 0.863725\n",
      "Validation accuracy: 0.8299\n",
      "Saved new best model with accuracy: 0.8299\n",
      "Epoch 30: Training accuracy = 0.86495\n",
      "Validation accuracy: 0.8334\n",
      "Saved new best model with accuracy: 0.8334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 83.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8346, 0.1654)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "from resnet import ResNet18\n",
    "resnet18 = ResNet18()\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet18.linear = nn.Linear(resnet18.linear.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=resnet18, num_epochs=30, model_path=\"resnet18.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "resnet18 = load_model(resnet18, \"resnet18.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet18, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f6ec1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiepnguyen/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hiepnguyen/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 77.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7746, 0.2254)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model checkpoint\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "resnet34.fc = nn.Linear(resnet34.fc.in_features, 10)\n",
    "resnet34 = load_model(resnet34, \"resnet34.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet34, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633b6865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training accuracy = 0.349975\n",
      "Validation accuracy: 0.4549\n",
      "Saved new best model with accuracy: 0.4549\n",
      "Epoch 2: Training accuracy = 0.450875\n",
      "Validation accuracy: 0.5104\n",
      "Saved new best model with accuracy: 0.5104\n",
      "Epoch 3: Training accuracy = 0.51555\n",
      "Validation accuracy: 0.5579\n",
      "Saved new best model with accuracy: 0.5579\n",
      "Epoch 4: Training accuracy = 0.549075\n",
      "Validation accuracy: 0.5825\n",
      "Saved new best model with accuracy: 0.5825\n",
      "Epoch 5: Training accuracy = 0.5779\n",
      "Validation accuracy: 0.5937\n",
      "Saved new best model with accuracy: 0.5937\n",
      "Epoch 6: Training accuracy = 0.597975\n",
      "Validation accuracy: 0.5907\n",
      "Epoch 7: Training accuracy = 0.62\n",
      "Validation accuracy: 0.6178\n",
      "Saved new best model with accuracy: 0.6178\n",
      "Epoch 8: Training accuracy = 0.6408\n",
      "Validation accuracy: 0.6522\n",
      "Saved new best model with accuracy: 0.6522\n",
      "Epoch 9: Training accuracy = 0.6553\n",
      "Validation accuracy: 0.6833\n",
      "Saved new best model with accuracy: 0.6833\n",
      "Epoch 10: Training accuracy = 0.672275\n",
      "Validation accuracy: 0.6717\n",
      "Epoch 11: Training accuracy = 0.68845\n",
      "Validation accuracy: 0.6595\n",
      "Epoch 12: Training accuracy = 0.697425\n",
      "Validation accuracy: 0.7105\n",
      "Saved new best model with accuracy: 0.7105\n",
      "Epoch 13: Training accuracy = 0.7134\n",
      "Validation accuracy: 0.7163\n",
      "Saved new best model with accuracy: 0.7163\n",
      "Epoch 14: Training accuracy = 0.7218\n",
      "Validation accuracy: 0.719\n",
      "Saved new best model with accuracy: 0.7190\n",
      "Epoch 15: Training accuracy = 0.733325\n",
      "Validation accuracy: 0.7303\n",
      "Saved new best model with accuracy: 0.7303\n",
      "Epoch 16: Training accuracy = 0.741525\n",
      "Validation accuracy: 0.7276\n",
      "Epoch 17: Training accuracy = 0.748275\n",
      "Validation accuracy: 0.7422\n",
      "Saved new best model with accuracy: 0.7422\n",
      "Epoch 18: Training accuracy = 0.7541\n",
      "Validation accuracy: 0.7296\n",
      "Epoch 19: Training accuracy = 0.763325\n",
      "Validation accuracy: 0.7457\n",
      "Saved new best model with accuracy: 0.7457\n",
      "Epoch 20: Training accuracy = 0.769625\n",
      "Validation accuracy: 0.7639\n",
      "Saved new best model with accuracy: 0.7639\n",
      "Epoch 21: Training accuracy = 0.77355\n",
      "Validation accuracy: 0.7434\n",
      "Epoch 22: Training accuracy = 0.7765\n",
      "Validation accuracy: 0.7637\n",
      "Epoch 23: Training accuracy = 0.7844\n",
      "Validation accuracy: 0.7775\n",
      "Saved new best model with accuracy: 0.7775\n",
      "Epoch 24: Training accuracy = 0.78935\n",
      "Validation accuracy: 0.7665\n",
      "Epoch 25: Training accuracy = 0.792125\n",
      "Validation accuracy: 0.7616\n",
      "Epoch 26: Training accuracy = 0.796025\n",
      "Validation accuracy: 0.7758\n",
      "Epoch 27: Training accuracy = 0.7996\n",
      "Validation accuracy: 0.777\n",
      "Epoch 28: Training accuracy = 0.80335\n",
      "Validation accuracy: 0.7751\n",
      "Epoch 29: Training accuracy = 0.805775\n",
      "Validation accuracy: 0.7942\n",
      "Saved new best model with accuracy: 0.7942\n",
      "Epoch 30: Training accuracy = 0.80765\n",
      "Validation accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 81.49%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8149, 0.1851)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model architecture\n",
    "from efficientNet import EfficientNetV2, efficientnet_v2_configs\n",
    "model_variant = 'efficientnet_v2_s'  # Choose between 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l'\n",
    "efficientv2s = EfficientNetV2(num_classes=10, architecture_config=efficientnet_v2_configs[model_variant]).to(device)\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "# resnet18.linear = nn.Linear(resnet18.linear.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=efficientv2s, num_epochs=30, model_path=\"efficientv2s.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "efficientv2s = load_model(efficientv2s, \"efficientv2s.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=efficientv2s, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6910f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 81.49%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8149, 0.1851)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_variant = 'efficientnet_v2_s'  # Choose between 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l'\n",
    "testModel = EfficientNetV2(num_classes=10, architecture_config=efficientnet_v2_configs[model_variant]).to(device)\n",
    "testModel = load_model(testModel, \"efficientv2s.pth\", device=device)\n",
    "test(model=testModel, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "024743cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training accuracy = 0.263975\n",
      "Validation accuracy: 0.3304\n",
      "Saved new best model with accuracy: 0.3304\n",
      "Epoch 2: Training accuracy = 0.335425\n",
      "Validation accuracy: 0.3923\n",
      "Saved new best model with accuracy: 0.3923\n",
      "Epoch 3: Training accuracy = 0.4019\n",
      "Validation accuracy: 0.4272\n",
      "Saved new best model with accuracy: 0.4272\n",
      "Epoch 4: Training accuracy = 0.4378\n",
      "Validation accuracy: 0.4438\n",
      "Saved new best model with accuracy: 0.4438\n",
      "Epoch 5: Training accuracy = 0.473625\n",
      "Validation accuracy: 0.4856\n",
      "Saved new best model with accuracy: 0.4856\n",
      "Epoch 6: Training accuracy = 0.5025\n",
      "Validation accuracy: 0.5202\n",
      "Saved new best model with accuracy: 0.5202\n",
      "Epoch 7: Training accuracy = 0.525225\n",
      "Validation accuracy: 0.5316\n",
      "Saved new best model with accuracy: 0.5316\n",
      "Epoch 8: Training accuracy = 0.550925\n",
      "Validation accuracy: 0.5509\n",
      "Saved new best model with accuracy: 0.5509\n",
      "Epoch 9: Training accuracy = 0.56835\n",
      "Validation accuracy: 0.5875\n",
      "Saved new best model with accuracy: 0.5875\n",
      "Epoch 10: Training accuracy = 0.594025\n",
      "Validation accuracy: 0.5931\n",
      "Saved new best model with accuracy: 0.5931\n",
      "Epoch 11: Training accuracy = 0.6082\n",
      "Validation accuracy: 0.6178\n",
      "Saved new best model with accuracy: 0.6178\n",
      "Epoch 12: Training accuracy = 0.6237\n",
      "Validation accuracy: 0.6278\n",
      "Saved new best model with accuracy: 0.6278\n",
      "Epoch 13: Training accuracy = 0.63895\n",
      "Validation accuracy: 0.6191\n",
      "Epoch 14: Training accuracy = 0.6536\n",
      "Validation accuracy: 0.638\n",
      "Saved new best model with accuracy: 0.6380\n",
      "Epoch 15: Training accuracy = 0.66295\n",
      "Validation accuracy: 0.6635\n",
      "Saved new best model with accuracy: 0.6635\n",
      "Epoch 16: Training accuracy = 0.67505\n",
      "Validation accuracy: 0.6807\n",
      "Saved new best model with accuracy: 0.6807\n",
      "Epoch 17: Training accuracy = 0.68435\n",
      "Validation accuracy: 0.6792\n",
      "Epoch 18: Training accuracy = 0.694875\n",
      "Validation accuracy: 0.6866\n",
      "Saved new best model with accuracy: 0.6866\n",
      "Epoch 19: Training accuracy = 0.707025\n",
      "Validation accuracy: 0.6989\n",
      "Saved new best model with accuracy: 0.6989\n",
      "Epoch 20: Training accuracy = 0.715825\n",
      "Validation accuracy: 0.705\n",
      "Saved new best model with accuracy: 0.7050\n",
      "Epoch 21: Training accuracy = 0.722925\n",
      "Validation accuracy: 0.7101\n",
      "Saved new best model with accuracy: 0.7101\n",
      "Epoch 22: Training accuracy = 0.731675\n",
      "Validation accuracy: 0.7226\n",
      "Saved new best model with accuracy: 0.7226\n",
      "Epoch 23: Training accuracy = 0.734675\n",
      "Validation accuracy: 0.7248\n",
      "Saved new best model with accuracy: 0.7248\n",
      "Epoch 24: Training accuracy = 0.74275\n",
      "Validation accuracy: 0.7101\n",
      "Epoch 25: Training accuracy = 0.74945\n",
      "Validation accuracy: 0.7287\n",
      "Saved new best model with accuracy: 0.7287\n",
      "Epoch 26: Training accuracy = 0.7525\n",
      "Validation accuracy: 0.7233\n",
      "Epoch 27: Training accuracy = 0.762775\n",
      "Validation accuracy: 0.7402\n",
      "Saved new best model with accuracy: 0.7402\n",
      "Epoch 28: Training accuracy = 0.7665\n",
      "Validation accuracy: 0.7456\n",
      "Saved new best model with accuracy: 0.7456\n",
      "Epoch 29: Training accuracy = 0.769275\n",
      "Validation accuracy: 0.7403\n",
      "Epoch 30: Training accuracy = 0.77515\n",
      "Validation accuracy: 0.7336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 76.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7614, 0.2386)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model architecture\n",
    "from efficientNet import EfficientNetV2, efficientnet_v2_configs\n",
    "model_variant = 'efficientnet_v2_m'  # Choose between 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l'\n",
    "efficientv2m = EfficientNetV2(num_classes=10, architecture_config=efficientnet_v2_configs[model_variant]).to(device)\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "# resnet18.linear = nn.Linear(resnet18.linear.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=efficientv2m, num_epochs=30, model_path=\"efficientv2m.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "efficientv2m = load_model(efficientv2m, \"efficientv2m.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=efficientv2m, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f9f6e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hiepnguyen/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hiepnguyen/Projects/590 Model Stealing/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/_6/p9gp3zw14dzd_gfn0862fgg00000gn/T/ipykernel_32517/269044466.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on clean test set: 83.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8334, 0.1666)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model checkpoint\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
    "resnet18 = load_model(resnet18, \"resnet18x.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet18, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662a5a10-ba13-450a-b843-98ee0d4bc086",
   "metadata": {
    "id": "662a5a10-ba13-450a-b843-98ee0d4bc086"
   },
   "source": [
    "## Experiment 1: Untargeted 8x8 patch attack on ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab68097-7b0b-4dab-93ff-34b147b0be5e",
   "metadata": {
    "id": "cab68097-7b0b-4dab-93ff-34b147b0be5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate adversarial patch\n",
    "patch_untargeted_size8 = generate_adversarial_patch(model=resnet18, patch_size=8)\n",
    "\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_untargeted_size8)\n",
    "\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_untargeted_size8)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb2a1e-f6d6-4ac9-bf43-bf35070726c0",
   "metadata": {
    "id": "7ccb2a1e-f6d6-4ac9-bf43-bf35070726c0"
   },
   "source": [
    "## Experiment 2: The effect of patch size on untargeted attack success rate for ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a4745-2d7c-4a1b-ac47-d26138fc52c4",
   "metadata": {
    "id": "4f7a4745-2d7c-4a1b-ac47-d26138fc52c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate untargeteded ASR for patches of various sizes and plot patch size vs. untargeted ASR\n",
    "patch_sizes = [3, 5, 7, 16]\n",
    "untargetted_asr_results = {}\n",
    "\n",
    "for size in patch_sizes:\n",
    "  patch = generate_adversarial_patch(model=resnet18, patch_size=size)\n",
    "  visualize_patch(patch)\n",
    "  adversarial_accuracy, untargetted_asr = test(model=resnet18, patch=patch)\n",
    "  untargetted_asr_results[size] = untargetted_asr\n",
    "\n",
    "plot_asr_vs_patch_size(patch_sizes, untargetted_asr_results)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c0bc71-330c-436a-8dbd-d16dfe7f35ef",
   "metadata": {
    "id": "08c0bc71-330c-436a-8dbd-d16dfe7f35ef"
   },
   "source": [
    "## Experiment 3: Targeted patch attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yR8VesXiLceO",
   "metadata": {
    "id": "yR8VesXiLceO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate targeted adversarial patch\n",
    "patch_targeted_size8 = generate_adversarial_patch(model=resnet18, patch_size=8, target_class=5)\n",
    "\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_targeted_size8)\n",
    "\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d32b237-5078-49d4-a317-edc7631d2e98",
   "metadata": {
    "id": "0d32b237-5078-49d4-a317-edc7631d2e98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_targeted_asr_vs_patch_size(model, target_class):\n",
    "  print(f\"\\nRUNNING EXPERIMENTS FOR TARGET CLASS {target_class}\\n\")\n",
    "  patch_sizes = [3, 5, 7, 16]\n",
    "  targetted_asr_results = {}\n",
    "  for size in patch_sizes:\n",
    "    patch = generate_adversarial_patch(model=model, patch_size=size, target_class=target_class)\n",
    "    visualize_patch(patch)\n",
    "    adversarial_accuracy, untargetted_asr, targetted_asr = test(model=resnet18, patch=patch, target_class=target_class)\n",
    "    targetted_asr_results[size] = targetted_asr\n",
    "  plot_asr_vs_patch_size(patch_sizes, targetted_asr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_AhlWWzD3XFG",
   "metadata": {
    "id": "_AhlWWzD3XFG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target_class in range(10):\n",
    "  plot_targeted_asr_vs_patch_size(resnet18, target_class)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad9912-b17e-4dcb-ab2e-f3ce64c117be",
   "metadata": {
    "id": "aaad9912-b17e-4dcb-ab2e-f3ce64c117be"
   },
   "source": [
    "## Experiment 4: Transferring patches to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2acfab8-fbaa-40ce-9d8d-0c57d3c223d2",
   "metadata": {
    "id": "e2acfab8-fbaa-40ce-9d8d-0c57d3c223d2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "resnet50 = models.resnet50(weights=\"DEFAULT\")\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=resnet50, num_epochs=30, model_path=\"resnet50.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "resnet50 = load_model(resnet50, \"resnet50.pth\", device=device)\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet50, patch=None, target_class=None)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\nTESTING PATCH TRANSFER FROM RESNET18 TO RESNET50\")\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=resnet50, patch=patch_untargeted_size8, target_class=None)\n",
    "\n",
    "# Targeted Attack\n",
    "test(model=resnet50, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64005c4-e6c2-435a-928e-2e0d96038cc0",
   "metadata": {
    "id": "a64005c4-e6c2-435a-928e-2e0d96038cc0"
   },
   "source": [
    "### Test untarget & target attack on VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80466fd-f3f7-4fb7-8d44-c9544dd0346b",
   "metadata": {
    "id": "c80466fd-f3f7-4fb7-8d44-c9544dd0346b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "vgg19 = models.vgg19(weights=\"DEFAULT\")\n",
    "\n",
    "# Get the number of input features to the classifier\n",
    "num_features = vgg19.classifier[-1].in_features\n",
    "\n",
    "# Replace the last layer (classifier) for CIFAR-10, which has 10 classes\n",
    "vgg19.classifier[-1] = nn.Linear(num_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=vgg19, num_epochs=30, model_path=\"vgg19.pth\")\n",
    "\n",
    "# Load best model checkpoint\n",
    "vgg19 = load_model(vgg19, \"vgg19.pth\")\n",
    "\n",
    "# Test model performance on clean test dataset\n",
    "test(model=vgg19, patch=None, target_class=None)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\nTESTING PATCH TRANSFER FROM RESNET18 TO VGG19\")\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=vgg19, patch=patch_untargeted_size8, target_class=None)\n",
    "\n",
    "# Targeted Attack\n",
    "test(model=vgg19, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d9869-859c-41f6-81ec-68354ee9f502",
   "metadata": {
    "id": "4d7d9869-859c-41f6-81ec-68354ee9f502"
   },
   "source": [
    "### Test untarget & target attack on DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dc4b4-9a41-4aea-8fea-67c829b7192f",
   "metadata": {
    "id": "864dc4b4-9a41-4aea-8fea-67c829b7192f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "densenet121 = models.densenet121(weights=\"DEFAULT\")\n",
    "\n",
    "num_features = densenet121.classifier.in_features  # Get the number of input features\n",
    "densenet121.classifier = nn.Linear(num_features, 10)  # Replace the classifier for CIFAR-10\n",
    "\n",
    "# Finetune the model\n",
    "fine_tune_for_cifar10(model=densenet121, num_epochs=60, model_path=\"densenet121.pth\",lr=0.05)\n",
    "\n",
    "# Load best model checkpoint\n",
    "densenet121 = load_model(densenet121, \"densenet121.pth\")\n",
    "# Test model performance on clean test dataset\n",
    "test(model=densenet121, patch=None, target_class=None)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\nTESTING PATCH TRANSFER FROM RESNET18 TO DENSENET121\")\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=densenet121, patch=patch_untargeted_size8, target_class=None)\n",
    "# Targeted Attack\n",
    "test(model=densenet121, patch=patch_targeted_size8, target_class=5)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3068d4-fd83-4177-b9e0-56666519c779",
   "metadata": {
    "id": "8b3068d4-fd83-4177-b9e0-56666519c779",
    "outputId": "56a4eaa2-de12-47d9-f7e1-b98de203b83d"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Define the table data\n",
    "table_data = [\n",
    "    [\"Model\", \"Model Accuracy\", \"Untargeted ASR\", \"Targeted ASR\"],\n",
    "    [\"ResNet18\", 0.8314, 0.6688, 0.7954],\n",
    "    [\"ResNet50\", 0.8680, 0.5792, 0.1465],\n",
    "    [\"VGG19\", 0.8843, 0.6252, 0.0892],\n",
    "    [\"DenseNet121\", 0.7008, 0.5744, 0.0423]\n",
    "\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7485f6",
   "metadata": {
    "id": "dd7485f6"
   },
   "source": [
    "## Experiment 5: Creating patches that are robust to more transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb8452f4",
   "metadata": {
    "id": "eb8452f4"
   },
   "outputs": [],
   "source": [
    "# Apply patch to a batch of images with additional transformations (rotation, horizontal flip, vertical flip, color inversion)\n",
    "def apply_extension(patch, batch_of_images):\n",
    "    num_images = batch_of_images.shape[0]\n",
    "    patch_size = patch.shape[1]\n",
    "\n",
    "    # Iterate through each image in the batch\n",
    "    for i in range(num_images):\n",
    "        # Rotate the patch by a random number of degrees\n",
    "        degree = random.uniform(0, 360)\n",
    "        patch_rotated = TF.rotate(patch, angle=degree)\n",
    "\n",
    "        # Apply horizontal flip with 50% probability\n",
    "        if random.random() > 0.5:\n",
    "            patch_rotated = TF.hflip(patch_rotated)\n",
    "\n",
    "        # Apply vertical flip with 50% probability\n",
    "        if random.random() > 0.5:\n",
    "            patch_rotated = TF.vflip(patch_rotated)\n",
    "\n",
    "        # Apply color inversion with 50% probability\n",
    "        if random.random() > 0.5:\n",
    "            patch_rotated = TF.invert(patch_rotated)\n",
    "\n",
    "        # Randomly choose an (x, y) coordinate on the 32x32 CIFAR-10 image\n",
    "        # This coordinate will be where the top left corner of the rotated patch goes\n",
    "        top_left_x = random.randint(0, 31 - patch_size)\n",
    "        top_left_y = random.randint(0, 31 - patch_size)\n",
    "\n",
    "        # Apply the randomly transformed patch at the random location\n",
    "        batch_of_images[i, :, top_left_x:top_left_x+patch_size, top_left_y:top_left_y+patch_size] = patch_rotated\n",
    "\n",
    "    return batch_of_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373a6df",
   "metadata": {
    "id": "7373a6df"
   },
   "outputs": [],
   "source": [
    "# # Load pre-trained model\n",
    "# resnet18ex = models.resnet18(weights=\"DEFAULT\")\n",
    "\n",
    "# # ResNet is trained on ImageNet, which has 1000 classes\n",
    "# # So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "# resnet18ex.fc = nn.Linear(resnet18ex.fc.in_features, 10)\n",
    "\n",
    "# # Finetune the model\n",
    "# fine_tune_for_cifar10(model=resnet18ex, num_epochs=30, model_path=\"resnet18ex.pth\")\n",
    "# # Load best model checkpoint\n",
    "# resnet18ex = load_model(resnet18ex, \"resnet18ex.pth\", device=device)\n",
    "# # Test model performance on clean test dataset\n",
    "test(model=resnet18, patch=None, target_class=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa653734",
   "metadata": {
    "id": "aa653734",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate adversarial patch\n",
    "patch_untarget_ex = generate_adversarial_patch(model=resnet18, patch_size=8, target_class=None, num_epochs=10, lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_untarget_ex)\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254471df",
   "metadata": {
    "id": "254471df",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate adversarial patch\n",
    "patch_target_ex = generate_adversarial_patch(model=resnet18, patch_size=8, target_class=5, num_epochs=10, lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "# Visualize the generated patch\n",
    "visualize_patch(patch_target_ex)\n",
    "# Test adversarial success rate on test dataset\n",
    "test(model=resnet18, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e061db6-872e-4755-9e6c-1209a68b9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "vgg19 = models.vgg19(weights=\"DEFAULT\")\n",
    "\n",
    "# Get the number of input features to the classifier\n",
    "num_features = vgg19.classifier[-1].in_features\n",
    "\n",
    "# Replace the last layer (classifier) for CIFAR-10, which has 10 classes\n",
    "vgg19.classifier[-1] = nn.Linear(num_features, 10)\n",
    "\n",
    "# Finetune the model\n",
    "# fine_tune_for_cifar10(model=vgg19, num_epochs=30, model_path=\"vgg19.pth\")\n",
    "# Load best model checkpoint\n",
    "vgg19 = load_model(vgg19, \"vgg19.pth\", device=device)\n",
    "# Test model performance on clean test dataset\n",
    "test(model=vgg19, patch=None, target_class=None, apply=apply_extension)\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=vgg19, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "# Targeted Attack\n",
    "test(model=vgg19, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ad32f-2faa-413b-96ab-dd80f126c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "densenet121 = models.densenet121(weights=\"DEFAULT\")\n",
    "\n",
    "num_features = densenet121.classifier.in_features  # Get the number of input features\n",
    "densenet121.classifier = nn.Linear(num_features, 10)  # Replace the classifier for CIFAR-10\n",
    "\n",
    "# Finetune the model\n",
    "# fine_tune_for_cifar10(model=densenet121, num_epochs=30, model_path=\"densenet121.pth\")\n",
    "# Load best model checkpoint\n",
    "densenet121 = load_model(densenet121, \"densenet121.pth\", device=device)\n",
    "# Test model performance on clean test dataset\n",
    "test(model=densenet121, patch=None, target_class=None, apply=apply_extension)\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=densenet121, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "# Targeted Attack\n",
    "test(model=densenet121, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416216a-cdf5-474e-a208-a4feb0a544f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "resnet50 = models.resnet50(weights=\"DEFAULT\")\n",
    "\n",
    "# ResNet is trained on ImageNet, which has 1000 classes\n",
    "# So we need to modify the output layer for CIFAR-10, which has 10 classes\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 10)\n",
    "# Load best model checkpoint\n",
    "resnet50 = load_model(resnet50, \"resnet50.pth\", device=device)\n",
    "# Test model performance on clean test dataset\n",
    "test(model=resnet50, patch=None, target_class=None, apply=apply_extension)\n",
    "\n",
    "# Untargeted Attack\n",
    "test(model=resnet50, patch=patch_untarget_ex, target_class=None, apply=apply_extension)\n",
    "# Targeted Attack\n",
    "test(model=resnet50, patch=patch_target_ex, target_class=5, apply=apply_extension)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23733847-fc61-4b3c-96ee-8629f5b78a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the table data\n",
    "table_data = [\n",
    "    [\"Model\", \"Model Accuracy\", \"Untargeted ASR\", \"Targeted ASR\"],\n",
    "    [\"ResNet18\", 0.8314, 0.6727, 0.3592],\n",
    "    [\"ResNet50\", 0.8680, 0.5024, 0.2193],\n",
    "    [\"VGG19\", 0.8843, 0.6930, 0.1035],\n",
    "    [\"DenseNet121\", 0.7008, 0.5750, 0.1206]\n",
    "\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(table_data, headers=\"firstrow\", tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af8021",
   "metadata": {
    "id": "f9af8021"
   },
   "source": [
    "### (Extension) Generate patches with side length of 3,5,7,10,13,16. Visualize patch_sizes v.s. untargeted ASR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42d2d7",
   "metadata": {
    "id": "6c42d2d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patch_sizes = [3, 5, 7, 10, 13, 16]\n",
    "untargetted_asr_results = {}\n",
    "for size in patch_sizes:\n",
    "  patch = generate_adversarial_patch(model=resnet18, patch_size=size, target_class=None, num_epochs=10,\\\n",
    "                                      lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "  visualize_patch(patch)\n",
    "  adversarial_accuracy, untargetted_asr = test(model=resnet18, patch=patch, target_class=None, apply=apply_extension)\n",
    "  untargetted_asr_results[size] = untargetted_asr\n",
    "plot_asr_vs_patch_size(patch_sizes, untargetted_asr_results)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1fd56",
   "metadata": {
    "id": "78c1fd56"
   },
   "source": [
    "### (Extension) Generate patches with side length of 3,5,7,10,13,16. Visualize patch_sizes v.s. targeted ASR. Target class is set to 5 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b05dcf",
   "metadata": {
    "id": "27b05dcf"
   },
   "outputs": [],
   "source": [
    "patch_sizes = [3, 5, 7, 10, 13, 16]\n",
    "targetted_asr_results = {}\n",
    "for size in patch_sizes:\n",
    "  patch = generate_adversarial_patch(model=resnet18, patch_size=size, target_class=5, num_epochs=10, \\\n",
    "                                     lr=1e-1, momentum=0.8, apply=apply_extension)\n",
    "  visualize_patch(patch)\n",
    "  adversarial_accuracy, untargetted_asr, targetted_asr = test(model=resnet18, patch=patch, target_class=5, apply=apply_extension)\n",
    "  targetted_asr_results[size] = targetted_asr\n",
    "plot_asr_vs_patch_size(patch_sizes, targetted_asr_results)\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")\n",
    "test(model=resnet18, patch=None, target_class=None)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7c79a-9aca-4cff-ab47-be95925499ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3dd60-661b-4cc1-a07d-d0060aed2e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
